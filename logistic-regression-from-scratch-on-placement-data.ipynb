{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10522763,"sourceType":"datasetVersion","datasetId":6512577}],"dockerImageVersionId":30839,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport math\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport plotly.express as px\n%matplotlib inline\nimport pprint\nimport pickle\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:05:49.903265Z","iopub.execute_input":"2025-03-06T09:05:49.903778Z","iopub.status.idle":"2025-03-06T09:05:49.931947Z","shell.execute_reply.started":"2025-03-06T09:05:49.903718Z","shell.execute_reply":"2025-03-06T09:05:49.930870Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In this project we are implementing logistic regression from scratch i.e. without using sklearn library. First we load data sets into pandas dataframe","metadata":{}},{"cell_type":"code","source":"myplacement_data=pd.read_csv('/kaggle/input/placement-prediction-dataset/placementdata.csv')\nmyplacement_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:05:49.933082Z","iopub.execute_input":"2025-03-06T09:05:49.933413Z","iopub.status.idle":"2025-03-06T09:05:49.961705Z","shell.execute_reply.started":"2025-03-06T09:05:49.933379Z","shell.execute_reply":"2025-03-06T09:05:49.960750Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exploratory Data Analysis(EDA)\n\nNow we are analysing the given data by plotting different graphs.","metadata":{}},{"cell_type":"code","source":"myplacement_data.describe().T","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:05:49.963275Z","iopub.execute_input":"2025-03-06T09:05:49.963630Z","iopub.status.idle":"2025-03-06T09:05:49.997999Z","shell.execute_reply.started":"2025-03-06T09:05:49.963594Z","shell.execute_reply":"2025-03-06T09:05:49.996872Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"myplacement_data.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:05:49.999343Z","iopub.execute_input":"2025-03-06T09:05:49.999627Z","iopub.status.idle":"2025-03-06T09:05:50.008988Z","shell.execute_reply.started":"2025-03-06T09:05:49.999602Z","shell.execute_reply":"2025-03-06T09:05:50.007824Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mypalette=['#034247','#051ceb']\nsns.displot(\n    myplacement_data, x=\"CGPA\", col=\"Projects\", row=\"PlacementStatus\",\n     height=3, facet_kws=dict(margin_titles=True),hue=\"PlacementStatus\",palette=mypalette\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:05:50.009979Z","iopub.execute_input":"2025-03-06T09:05:50.010296Z","iopub.status.idle":"2025-03-06T09:05:53.597913Z","shell.execute_reply.started":"2025-03-06T09:05:50.010271Z","shell.execute_reply":"2025-03-06T09:05:53.596904Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.set_theme(style=\"whitegrid\")\ng = sns.catplot(\n    data=myplacement_data, kind=\"count\",\n    x=\"AptitudeTestScore\",hue=\"PlacementStatus\",\n    palette=['#0792b5','#0747b5'], alpha=.6, height=6\n)\ng.despine(left=True)\ng.set_axis_labels(\"AptitudeTestScore\", \"\");\ng.set_xticklabels(rotation=90)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:05:53.598806Z","iopub.execute_input":"2025-03-06T09:05:53.599087Z","iopub.status.idle":"2025-03-06T09:05:54.658108Z","shell.execute_reply.started":"2025-03-06T09:05:53.599061Z","shell.execute_reply":"2025-03-06T09:05:54.656959Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.set_theme(style=\"whitegrid\")\n\ng = sns.catplot(\n    data=myplacement_data, kind=\"count\",\n    x=\"SSC_Marks\",hue=\"PlacementStatus\",\n    palette=['#0792b5','#0747b5'], alpha=.6, height=6\n)\ng.despine(left=True)\ng.set_axis_labels(\"SSC_Marks\", \"\")\ng.set_xticklabels(rotation=90)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:05:54.659367Z","iopub.execute_input":"2025-03-06T09:05:54.659750Z","iopub.status.idle":"2025-03-06T09:05:55.881371Z","shell.execute_reply.started":"2025-03-06T09:05:54.659696Z","shell.execute_reply":"2025-03-06T09:05:55.880137Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.set_theme(style=\"whitegrid\")\n\ng = sns.catplot(\n    data=myplacement_data, kind=\"count\",\n    x=\"SoftSkillsRating\",hue=\"PlacementStatus\",\n    palette=['#0792b5','#0747b5'], alpha=.6, height=6\n)\ng.despine(left=True)\ng.set_axis_labels(\"SoftSkillsRating\", \"\")\ng.legend.set_title(\"\")\ng.set_xticklabels(rotation=90)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:05:55.882397Z","iopub.execute_input":"2025-03-06T09:05:55.882747Z","iopub.status.idle":"2025-03-06T09:05:56.685460Z","shell.execute_reply.started":"2025-03-06T09:05:55.882695Z","shell.execute_reply":"2025-03-06T09:05:56.684281Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"Here we encode the categorical data columns into 0s and 1s so that we can use those columns in correlation matrix as we cannot use categorical data in correlation matrix.","metadata":{}},{"cell_type":"code","source":"placement_data=myplacement_data.copy()\nplacement_data['ExtracurricularActivities'] = (placement_data['ExtracurricularActivities'] == 'Yes').astype(int)\nplacement_data['PlacementTraining'] = (placement_data['PlacementTraining'] == 'Yes').astype(int)\nplacement_data['PlacementStatus'] = (placement_data['PlacementStatus'] == 'Placed').astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:05:56.688123Z","iopub.execute_input":"2025-03-06T09:05:56.688399Z","iopub.status.idle":"2025-03-06T09:05:56.698447Z","shell.execute_reply.started":"2025-03-06T09:05:56.688376Z","shell.execute_reply":"2025-03-06T09:05:56.697454Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corr=placement_data.corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap='mako_r', vmax=.8, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5},annot = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:05:56.699914Z","iopub.execute_input":"2025-03-06T09:05:56.700228Z","iopub.status.idle":"2025-03-06T09:05:57.414704Z","shell.execute_reply.started":"2025-03-06T09:05:56.700194Z","shell.execute_reply":"2025-03-06T09:05:57.413783Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:05:57.416058Z","iopub.execute_input":"2025-03-06T09:05:57.416477Z","iopub.status.idle":"2025-03-06T09:05:57.435105Z","shell.execute_reply.started":"2025-03-06T09:05:57.416442Z","shell.execute_reply":"2025-03-06T09:05:57.433962Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get the absolute value of correlation of all columns with PlacementStatus\ntarget=abs(corr['PlacementStatus'])\n# Get highly correlated columns (threshold value=0.3)\ntarget = target[target>0.3]\n# Make a list of names of all columns that are highly correlated\nnames=[index for index,value in target.items()]\n# Remove the target variable from this\nnames.remove('PlacementStatus')\nprint(names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:05:57.436213Z","iopub.execute_input":"2025-03-06T09:05:57.436554Z","iopub.status.idle":"2025-03-06T09:05:57.450403Z","shell.execute_reply.started":"2025-03-06T09:05:57.436518Z","shell.execute_reply":"2025-03-06T09:05:57.449216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Lets define X and y, X has all highly correlated columns and y is target variable\nX = placement_data[names].values\ny = placement_data['PlacementStatus'].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:05:57.451455Z","iopub.execute_input":"2025-03-06T09:05:57.451817Z","iopub.status.idle":"2025-03-06T09:05:57.465849Z","shell.execute_reply.started":"2025-03-06T09:05:57.451789Z","shell.execute_reply":"2025-03-06T09:05:57.464990Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_test_split(X, y, random_state=42, test_size=0.2):\n    \"\"\"\n    Splits the data into training and testing sets.\n\n    Parameters:\n        X (numpy.ndarray): Features array of shape (n_samples, n_features).\n        y (numpy.ndarray): Target array of shape (n_samples,).\n        random_state (int): Seed for the random number generator. Default is 42.\n        test_size (float): Proportion of samples to include in the test set. Default is 0.2.\n\n    Returns:\n        Tuple[numpy.ndarray]: A tuple containing X_train, X_test, y_train, y_test.\n    \"\"\"\n    # Get number of samples \n    n_samples = X.shape[0]\n    # Set the seed for the random number genrator\n    np.random.seed(random_state)\n    # Shuffle the indices \n    shuffled_indices = np.random.permutation(np.arange(n_samples))\n    # Determine the size of test set\n    test_size = int(n_samples * test_size)\n    # Splitting into test and train indices\n    test_indices = shuffled_indices[:test_size]\n    train_indices = shuffled_indices[test_size:]\n    # Splitting into target variables and features into test and train \n    X_train,X_test = X[train_indices],X[test_indices]\n    y_train,y_test = y[train_indices], y[test_indices]\n    return X_train, X_test, y_train, y_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:05:57.466806Z","iopub.execute_input":"2025-03-06T09:05:57.467071Z","iopub.status.idle":"2025-03-06T09:05:57.480294Z","shell.execute_reply.started":"2025-03-06T09:05:57.467050Z","shell.execute_reply":"2025-03-06T09:05:57.479293Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:05:57.481403Z","iopub.execute_input":"2025-03-06T09:05:57.481773Z","iopub.status.idle":"2025-03-06T09:05:57.503295Z","shell.execute_reply.started":"2025-03-06T09:05:57.481716Z","shell.execute_reply":"2025-03-06T09:05:57.502041Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Standardize the data\nStandardization is a preprocessing technique used in machine learning to rescale and transform the features (variables) of a dataset to have a mean of 0 and a standard deviation of 1. It is also known as \"z-score normalization\" or \"z-score scaling.\"\n\n# How to Standardize Data\nThe standardization process involves the following steps:\n\nCalculate the mean (\nμ\n) and standard deviation (\nσ\n) for each feature in the dataset.\nFor each data point (sample), subtract the mean (\nμ\n) of the feature and then divide by the standard deviation (\nσ\n) of the feature.\nMathematically, the standardized value for a feature x in a dataset is calculated as:\n\nStandardized value = $\\frac{x-\\mu}{\\sigma}$\n\nHere, x is the original value of the feature, \nμ\n is the mean of the feature, and \nσ\n is the standard deviation of the feature.","metadata":{}},{"cell_type":"code","source":"def standardize_data(X_train, X_test):\n    \"\"\"\n    Standardizes the input data using mean and standard deviation.\n\n    Parameters:\n        X_train (numpy.ndarray): Training data.\n        X_test (numpy.ndarray): Testing data.\n\n    Returns:\n        Tuple of standardized training and testing data.\n    \"\"\"\n    mean = np.mean(X_train, axis=0)\n    std = np.std(X_train, axis=0)\n    \n    # Standardize the data\n    X_train = (X_train - mean) / std\n    X_test = (X_test - mean) / std\n    \n    return X_train, X_test\n\nX_train, X_test = standardize_data(X_train, X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:05:57.504432Z","iopub.execute_input":"2025-03-06T09:05:57.504847Z","iopub.status.idle":"2025-03-06T09:05:57.517501Z","shell.execute_reply.started":"2025-03-06T09:05:57.504808Z","shell.execute_reply":"2025-03-06T09:05:57.516304Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model implementation","metadata":{}},{"cell_type":"markdown","source":"## Logistic Regression\n\nLogistic Regression is used to solve classification problems binary as well as multiclass classification. We use sigmoid function in this model to squash the line at 0 and 1.\nThe following function represents the model :\n$$f_{w,b}(x)=g(w.x+b)$$\nIn this equation,$f_{w,b}(x)$ represents the predicted probability, w is the weight vector, b is the bias term, x is the input feature vector, and is the sigmoid function:\n$$g(z)=\\frac{1}{1+e^{-z}}$$\nTo train a logistic regression model, we aim to find the best values for the parameters (w,b)that best fit our dataset and provide accurate class probabilities.\n\n## Forward Pass\nThe forward pass computes the linear combination of input features  x with the weight vector  w and the bias term  b and then applies the sigmoid function to the result:\n$$z=w.x+b$$\n$$A=σ(z)A=\\sigma(z)$$\n## Cost Function\nThe cost function measures the error between the predicted probabilities and the true labels. In logistic regression, we use the binary cross-entropy loss function:\n$$J(w,b)=-\\frac{1}{m}\\sum_{i=1}^{m}\\left[ y_{i}log(f_{w,b}(x_{i}))+(1-y_{i})log(1-f_{w,b}(x_{i})) \\right]$$\nHere, m is the number of samples, $y_{i}$ is the true label of sample i, $f_{w,b}(x_{i})$ and  is the predicted probability of sample i belonging to the positive class.\n## Backward Pass (Gradient Computation)\nThe backward pass calculates the gradients of the cost function with respect to the parameters (w,b). These gradients are essential for updating the model parameters during training:\n$$\\frac{\\partial J(w,b)}{\\partial b} = \\frac{1}{m}\\sum_{i=1}^{m}(f_{w,b}(x_{i})-y_{i})$$\n$$\\frac{\\partial J(w,b)}{\\partial w} = \\frac{1}{m}\\sum_{i=1}^{m}(f_{w,b}(x_{i})-y_{i})x_{i}$$\n\nyou can find the derivation of above formula here [kaggle](https://www.kaggle.com/code/mansisharma9/derivation-of-logistic-regression-cost-function/)\n## Training Process\nThe training process involves iteratively updating the weight vector w and bias term b to minimize the cost function. This is typically done through an optimization algorithm like gradient descent. The update equations for parameters are:\n$$w\\gets w-\\alpha\\frac{\\partial J}{\\partial w}$$\n$$b\\gets b-\\alpha\\frac{\\partial J}{\\partial b}$$\n\nHere, α represents the learning rate, which controls the step size during parameter updates.\nBy iteratively performing the forward pass, computing the cost, performing the backward pass, and updating the parameters, the logistic regression model learns to make better predictions and fit the data.","metadata":{}},{"cell_type":"code","source":"def sigmoid(z):\n    \"\"\"\n    Compute the sigmoid function for a given input.\n\n    The sigmoid function is a mathematical function used in logistic regression and neural networks\n    to map any real-valued number to a value between 0 and 1.\n\n    Parameters:\n        z (float or numpy.ndarray): The input value(s) for which to compute the sigmoid.\n\n    Returns:\n        float or numpy.ndarray: The sigmoid of the input value(s).\n\n    Example:\n        >>> sigmoid(0)= 0.5\n    \"\"\"\n    \n    sigmoid_result = 1/(1+np.exp(-z))\n    return sigmoid_result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:05:57.518632Z","iopub.execute_input":"2025-03-06T09:05:57.518984Z","iopub.status.idle":"2025-03-06T09:05:57.525329Z","shell.execute_reply.started":"2025-03-06T09:05:57.518953Z","shell.execute_reply":"2025-03-06T09:05:57.524352Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class LogisticRegression :\n    \"\"\"\n    Logistic Regression model.\n\n    Parameters:\n        learning_rate (float): Learning rate for the model.\n\n    Methods:\n        initialize_parameter(): Initializes the parameters of the model.\n        sigmoid(z): Computes the sigmoid activation function for given input z.\n        forward(X): Computes forward propagation for given input X.\n        compute_cost(predictions): Computes the cost function for given predictions.\n        compute_gradient(predictions): Computes the gradients for the model using given predictions.\n        fit(X, y, iterations, plot_cost): Trains the model on given input X and labels y for specified iterations.\n        predict(X): Predicts the labels for given input X.\n    \"\"\"\n    def __init__(self, learning_rate=0.0001):\n        np.random.seed(1)\n        self.learning_rate = learning_rate #initialize the alpha\n\n    def initialize_parameter(self):\n        self.W = np.zeros(self.X.shape[1]) #initialize the weights\n        self.b = 0.0\n\n    def forward(self,X):\n        \"\"\"\n        Computes forward propagation for given input X.\n\n        Parameters:\n            X (numpy.ndarray): Input array features of dataset.\n\n        Returns:\n            numpy.ndarray: Output array sigmoid value for each point.\n        \"\"\"\n        Z=np.matmul(X,self.W) + self.b\n        A = sigmoid(Z)\n        return A\n\n    def compute_cost(self,predictions):\n        \"\"\"\n        Computes the cost function for given predictions.\n\n        Parameters:\n            predictions (numpy.ndarray): Predictions of the model.\n\n        Returns:\n            float: Cost of the model.\n        \"\"\"\n        m = self.X.shape[0]\n        #computing the cost we are adding small value of epsilon to avoid log0\n        cost = np.sum((-np.log(predictions + 1e-8)*self.y) + (-np.log(1-predictions + 1e-8))* (1 - self.y))\n        cost = cost/m\n        return cost\n\n    def compute_gradient(self,predictions):\n        \"\"\"\n        Computes the gradients for the model using given predictions.\n\n        Parameters:\n            predictions (numpy.ndarray): Predictions of the model.\n        \"\"\"\n        m=self.X.shape[0]\n        self.dW = np.matmul(self.X.T, (predictions - self.y))\n        self.dW = np.array([np.mean(grad) for grad in self.dW])\n        self.db = np.sum(np.subtract(predictions,self.y))\n        self.dW = self.dW * 1/m\n        self.db = self.db *1/m\n\n    def fit(self,X,y,iterations,plot_cost=True):\n        \"\"\"\n        Trains the model on given input X and labels y for specified iterations.\n\n        Parameters:\n            X (numpy.ndarray): Input features array of shape (n_samples, n )\n            y (numpy.ndarray): Labels array of shape (n_samples, 1)\n            iterations (int): Number of iterations for training.\n            plot_cost (bool): Whether to plot cost over iterations or not.\n\n        Returns:\n            None.\n        \"\"\"\n        self.X = X\n        self.y = y\n        self.initialize_parameter()#initialize the parameters\n        costs = []\n        for i in range(iterations):\n            predictions = self.forward(self.X)#forward propogation\n            cost = self.compute_cost(predictions)#compute the cost\n            costs.append(cost)\n            self.compute_gradient(predictions)#compute gradients\n            self.W = self.W - self.learning_rate * self.dW\n            self.b = self.b - self.learning_rate * self.db\n            #print cost every 100 iterations\n            if i % 10000 == 0:\n                print(\"Cost after iteration {}: {}\" .format(i,cost))\n\n        if plot_cost:\n            fig=px.line(y=costs,title=\"Cost vs Iteration\",template=\"plotly_dark\")\n            fig.update_layout(title_font_color=\"#41BEE9\", xaxis=dict(color=\"#41BEE9\",title=\"Iterations\"), \n                              yaxis=dict(color=\"#41BEE9\",title=\"cost\"))\n            fig.show()\n\n    def predict(self,X):\n        \"\"\"\n        Predicts the labels for given input X.\n\n        Parameters:\n            X (numpy.ndarray): Input features array.\n\n        Returns:\n            numpy.ndarray: Predicted labels.\n        \"\"\"\n        predictions = self.forward(X)\n        return np.round(predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:05:57.526281Z","iopub.execute_input":"2025-03-06T09:05:57.526687Z","iopub.status.idle":"2025-03-06T09:05:57.543136Z","shell.execute_reply.started":"2025-03-06T09:05:57.526651Z","shell.execute_reply":"2025-03-06T09:05:57.542124Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = LogisticRegression()\nmodel.fit(X_train, y_train,100000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:05:57.544018Z","iopub.execute_input":"2025-03-06T09:05:57.544390Z","iopub.status.idle":"2025-03-06T09:06:46.260410Z","shell.execute_reply.started":"2025-03-06T09:05:57.544355Z","shell.execute_reply":"2025-03-06T09:06:46.258215Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"model.pkl\", \"wb\") as f:\n    pickle.dump(model, f)\nwith open(\"model.pkl\", \"rb\") as f:\n    loaded_model = pickle.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:06:46.261468Z","iopub.execute_input":"2025-03-06T09:06:46.261789Z","iopub.status.idle":"2025-03-06T09:06:46.267486Z","shell.execute_reply.started":"2025-03-06T09:06:46.261756Z","shell.execute_reply":"2025-03-06T09:06:46.266554Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation\nIn classification tasks, it's crucial to evaluate the performance of your model. There are several metrics that can help you understand how well your model is performing. Here are four commonly used classification metrics:\n\n## Accuracy\n**Formula**:\n   $$Accuracy=\\frac{\\text{Number of correct predictions}}{\\text{Total number of predictions}}$$\n\n**Description**:\n\nAccuracy measures the proportion of correctly predicted instances out of all instances in a classification model.\nIt is a widely used metric for evaluating classification performance.\n\n**Interpretation**:\n\nA higher accuracy value indicates a better classification model.\nHowever, accuracy alone may not provide a complete picture, especially in imbalanced datasets.\n\n## Precision \n**Formula**:\n$$Precision=\\frac{\\text{True Positives}}{\\text{True Positives+False Positives}}$$\n**Description**:\n\nPrecision measures the proportion of true positive predictions out of all positive predictions made by the model.\nIt is a useful metric when the cost of false positives is high.\n\n**Interpretation**:\n\nHigher precision means the model makes fewer false positive predictions.\n\n## Recall (Sensitivity) \n\n**Formula**: \n$$Recall (Sensitivity)=\\frac{\\text{True Positives}}{\\text{True Positives + False Negatives}}$$\n**Description**:\n\nRecall, also known as sensitivity or true positive rate, measures the proportion of true positive predictions out of all actual positive instances in the dataset.\nIt is a valuable metric when it's essential to capture all positive instances.\n\n**Interpretation**: \n\nHigher recall means the model captures more of the actual positive instances.\n\n## F1-Score \n**Formula**:\n\n$$F1-Score = 2 ×\\frac{\\text{Precision × Recall}}{\\text{Precision + Recall}}\n$$\n\n**Description**:\n\nThe F1-Score is the harmonic mean of precision and recall.\nIt provides a balance between precision and recall, making it a suitable metric when there is a trade-off between false positives and false negatives.\n\n**Interpretation**:\n\nA higher F1-Score indicates a model that achieves a balance between precision and recall.","metadata":{}},{"cell_type":"code","source":"class ClassificationMetrics:\n    @staticmethod\n    def accuracy(y_true, y_pred):\n        \"\"\"\n        Computes the accuracy of a classification model.\n\n        Parameters:\n        y_true (numpy array): A numpy array of true labels for each data point.\n        y_pred (numpy array): A numpy array of predicted labels for each data point.\n\n        Returns:\n        float: The accuracy of the model, expressed as a percentage.\n        \"\"\"\n        y_true = y_true.flatten()\n        total_samples = len(y_true)\n        correct_predictions = np.sum(y_true == y_pred)\n        return (correct_predictions / total_samples)\n\n    @staticmethod\n    def precision(y_true, y_pred):\n        \"\"\"\n        Computes the precision of a classification model.\n\n        Parameters:\n        y_true (numpy array): A numpy array of true labels for each data point.\n        y_pred (numpy array): A numpy array of predicted labels for each data point.\n\n        Returns:\n        float: The precision of the model, which measures the proportion of true positive predictions\n        out of all positive predictions made by the model.\n        \"\"\"\n        true_positives = np.sum((y_true == 1) & (y_pred == 1))\n        false_positives = np.sum((y_true == 0) & (y_pred == 1))\n        return true_positives / (true_positives + false_positives)\n\n    @staticmethod\n    def recall(y_true, y_pred):\n        \"\"\"\n        Computes the recall (sensitivity) of a classification model.\n\n        Parameters:\n        y_true (numpy array): A numpy array of true labels for each data point.\n        y_pred (numpy array): A numpy array of predicted labels for each data point.\n\n        Returns:\n        float: The recall of the model, which measures the proportion of true positive predictions\n        out of all actual positive instances in the dataset.\n        \"\"\"\n        true_positives = np.sum((y_true == 1) & (y_pred == 1))\n        false_negatives = np.sum((y_true == 1) & (y_pred == 0))\n        return true_positives / (true_positives + false_negatives)\n\n    @staticmethod\n\n    def f1_score(y_true, y_pred):\n        \"\"\"\n        Computes the F1-score of a classification model.\n\n        Parameters:\n        y_true (numpy array): A numpy array of true labels for each data point.\n        y_pred (numpy array): A numpy array of predicted labels for each data point.\n\n        Returns:\n        float: The F1-score of the model, which is the harmonic mean of precision and recall.\n        \"\"\"\n        precision_value = ClassificationMetrics.precision(y_true, y_pred)\n        recall_value = ClassificationMetrics.recall(y_true, y_pred)\n        return 2 * (precision_value * recall_value) / (precision_value + recall_value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:06:46.268439Z","iopub.execute_input":"2025-03-06T09:06:46.268711Z","iopub.status.idle":"2025-03-06T09:06:46.281161Z","shell.execute_reply.started":"2025-03-06T09:06:46.268687Z","shell.execute_reply":"2025-03-06T09:06:46.280065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = loaded_model.predict(X_test)\naccuracy = ClassificationMetrics.accuracy(y_test, y_pred)\nprecision = ClassificationMetrics.precision(y_test, y_pred)\nrecall = ClassificationMetrics.recall(y_test, y_pred)\nf1_score = ClassificationMetrics.f1_score(y_test, y_pred)\n\nprint(f\"Accuracy: {accuracy:.2%}\")\nprint(f\"Precision: {precision:.2%}\")\nprint(f\"Recall: {recall:.2%}\")\nprint(f\"F1-Score: {f1_score:.2%}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:06:46.282324Z","iopub.execute_input":"2025-03-06T09:06:46.282672Z","iopub.status.idle":"2025-03-06T09:06:46.301231Z","shell.execute_reply.started":"2025-03-06T09:06:46.282641Z","shell.execute_reply":"2025-03-06T09:06:46.300175Z"}},"outputs":[],"execution_count":null}]}